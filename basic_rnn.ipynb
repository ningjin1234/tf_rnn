{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batchSize = 5\n",
    "maxNumSteps = 8\n",
    "embeddingSize = 3\n",
    "nNeurons = 4\n",
    "vocabulary_size = 10\n",
    "initEmbeddings = np.random.randn(vocabulary_size, embeddingSize)\n",
    "bias_trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "inputTokens = tf.placeholder(tf.int32, [batchSize, maxNumSteps])\n",
    "inputLens = tf.placeholder(tf.int32, [batchSize])\n",
    "targets = tf.placeholder(tf.float64, [batchSize])\n",
    "rnnCell = tf.nn.rnn_cell.BasicRNNCell(nNeurons)\n",
    "initState = rnnCell.zero_state(batchSize, tf.float64)\n",
    "\n",
    "embedding = tf.Variable(initEmbeddings, name='inputEmbeddings', trainable=False, dtype=tf.float64)\n",
    "inputData = tf.nn.embedding_lookup(embedding, inputTokens)\n",
    "\n",
    "raw_outputs, last_states = tf.nn.dynamic_rnn(\n",
    "    cell=rnnCell,\n",
    "    dtype=tf.float64,\n",
    "    sequence_length=inputLens,\n",
    "    inputs=inputData)\n",
    "    \n",
    "flattened_outputs = tf.reshape(raw_outputs, [-1, nNeurons])\n",
    "index = tf.range(0, batchSize) * maxNumSteps + inputLens - 1\n",
    "outputs = tf.gather(flattened_outputs, index)\n",
    "outputW = tf.get_variable(\"outputW\", [nNeurons, 1], dtype=tf.float64)\n",
    "outputB = tf.get_variable(\"outputB\", [1], dtype=tf.float64)\n",
    "prediction = tf.add(tf.matmul(outputs, outputW), outputB)\n",
    "loss = tf.reduce_sum(tf.pow(prediction-targets, 2)/batchSize)\n",
    "\n",
    "lr = tf.Variable(0.1, trainable=False)\n",
    "tvars = tf.trainable_variables()\n",
    "if not bias_trainable:\n",
    "    tvars = np.take(tvars, [0,2,3]).tolist() # exclude RNN bias from training\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "learningStep = optimizer.minimize(loss, var_list=tvars)\n",
    "initAll = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN/BasicRNNCell/Linear/Matrix:0\n",
      "[[ 0.42941295 -0.07258421 -0.54979762 -0.11436226]\n",
      " [ 0.61322717  0.03764971 -0.24182697 -0.36987435]\n",
      " [-0.58862103 -0.63002914  0.09251724 -0.54323472]\n",
      " [-0.57283322  0.64178415  0.62736614  0.1091234 ]\n",
      " [-0.1387797   0.14621779  0.26264562  0.11519057]\n",
      " [ 0.43270537 -0.27682909  0.11104942  0.60778161]\n",
      " [ 0.30884604 -0.5391706  -0.00791769  0.35584711]]\n",
      "RNN/BasicRNNCell/Linear/Bias:0\n",
      "[ 0.  0.  0.  0.]\n",
      "outputW:0\n",
      "[[ 0.15560042]\n",
      " [ 0.55991761]\n",
      " [ 0.25549454]\n",
      " [ 0.28202788]]\n",
      "outputB:0\n",
      "[-0.83189643]\n",
      "4.7232749571\n",
      "RNN/BasicRNNCell/Linear/Matrix:0\n",
      "[[ 0.39361403 -0.3548663  -0.64596807 -0.24474875]\n",
      " [ 0.61318321  0.15649813 -0.20737876 -0.30127714]\n",
      " [-0.57707762 -0.58114884  0.0933289  -0.53402564]\n",
      " [-0.58224216  0.69261914  0.63830254  0.15717213]\n",
      " [-0.14172636  0.09487458  0.24822881  0.07911065]\n",
      " [ 0.49856179 -0.26616252  0.13136916  0.57045825]\n",
      " [ 0.32198598 -0.48820845  0.00958399  0.39029228]]\n",
      "RNN/BasicRNNCell/Linear/Bias:0\n",
      "[ 0.  0.  0.  0.]\n",
      "outputW:0\n",
      "[[-0.00347323]\n",
      " [ 0.5632911 ]\n",
      " [ 0.51485884]\n",
      " [ 0.21606278]]\n",
      "outputB:0\n",
      "[-0.36860142]\n"
     ]
    }
   ],
   "source": [
    "# data = np.random.randn(batchSize, maxNumSteps, embeddingSize)\n",
    "data = np.random.randint(0, high=vocabulary_size-1, size=(batchSize, maxNumSteps))\n",
    "lens = [maxNumSteps for i in xrange(batchSize)]\n",
    "t = np.random.randn(batchSize)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(initAll)\n",
    "#     e = sess.run(embedding)\n",
    "#     print e\n",
    "#     print data\n",
    "#     s = sess.run(inputData, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print s\n",
    "#     l = sess.run(loss, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print l\n",
    "    for v in tf.trainable_variables():\n",
    "        print v.name\n",
    "        print sess.run(v)\n",
    "#     w = sess.run(outputW)\n",
    "#     b = sess.run(outputB)\n",
    "#     print w\n",
    "#     print b\n",
    "#     r = sess.run(raw_outputs, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print len(r), len(r[0])\n",
    "#     print r[:,-1]\n",
    "#     i = sess.run(index, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print i\n",
    "#     o = sess.run(outputs, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print o\n",
    "#     m = sess.run(tf.matmul(outputs, outputW), feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print m\n",
    "#     p = sess.run(prediction, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print p\n",
    "    sess.run(learningStep, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "    l = sess.run(loss, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "    print l\n",
    "    for v in tf.trainable_variables():\n",
    "        print v.name\n",
    "        print sess.run(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66335526],\n",
       "       [ 0.70219608],\n",
       "       [-0.58211488],\n",
       "       [ 0.07739599],\n",
       "       [ 0.10125138]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(r[:,-1], w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-85b0413392e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtvars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers, not list"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
