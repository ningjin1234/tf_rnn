{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize = 5\n",
    "maxNumSteps = 8\n",
    "embeddingSize = 3\n",
    "nNeurons = 4\n",
    "vocabulary_size = 10\n",
    "initEmbeddings = np.random.randn(vocabulary_size, embeddingSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "inputTokens = tf.placeholder(tf.int32, [batchSize, maxNumSteps])\n",
    "inputLens = tf.placeholder(tf.int32, [batchSize])\n",
    "targets = tf.placeholder(tf.float64, [batchSize])\n",
    "rnnCell = tf.nn.rnn_cell.BasicRNNCell(nNeurons)\n",
    "initState = rnnCell.zero_state(batchSize, tf.float64)\n",
    "\n",
    "embedding = tf.Variable(initEmbeddings, name='inputEmbeddings', trainable=False, dtype=tf.float64)\n",
    "inputData = tf.nn.embedding_lookup(embedding, inputTokens)\n",
    "\n",
    "raw_outputs, last_states = tf.nn.dynamic_rnn(\n",
    "    cell=rnnCell,\n",
    "    dtype=tf.float64,\n",
    "    sequence_length=inputLens,\n",
    "    inputs=inputData)\n",
    "    \n",
    "flattened_outputs = tf.reshape(raw_outputs, [-1, nNeurons])\n",
    "index = tf.range(0, batchSize) * maxNumSteps + inputLens - 1\n",
    "outputs = tf.gather(flattened_outputs, index)\n",
    "outputW = tf.get_variable(\"outputW\", [nNeurons, 1], dtype=tf.float64)\n",
    "outputB = tf.get_variable(\"outputB\", [1], dtype=tf.float64)\n",
    "prediction = tf.add(tf.matmul(outputs, outputW), outputB)\n",
    "loss = tf.reduce_sum(tf.pow(prediction-targets, 2)/batchSize)\n",
    "\n",
    "lr = tf.Variable(0.1, trainable=False)\n",
    "tvars = tf.trainable_variables()\n",
    "tvars = np.take(tvars, [0,2,3]).tolist() # exclude RNN bias from training\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "learningStep = optimizer.minimize(loss, var_list=tvars)\n",
    "initAll = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.80577191  0.52229679  0.93380249]\n",
      " [-0.84560716 -0.43266551  1.09092011]\n",
      " [-0.2683122  -0.23485634  0.75907219]\n",
      " [-0.24423481  0.58242155  0.9500426 ]\n",
      " [ 0.18173485 -0.04901824 -0.57453806]\n",
      " [-0.30975785  0.99402065 -1.20278396]\n",
      " [ 0.23538442  0.08246597  1.19941157]\n",
      " [ 0.65812436 -1.68136343  0.99296283]\n",
      " [-0.28339739 -3.33845653 -0.54183886]\n",
      " [-1.19780826 -0.36035379  0.67650091]]\n",
      "[[5 6 0 7 7 1 6 8]\n",
      " [0 1 8 0 4 1 8 2]\n",
      " [4 3 5 0 1 7 3 6]\n",
      " [6 1 8 0 7 8 4 7]\n",
      " [5 6 6 2 4 3 8 8]]\n",
      "[[[-0.30975785  0.99402065 -1.20278396]\n",
      "  [ 0.23538442  0.08246597  1.19941157]\n",
      "  [-0.80577191  0.52229679  0.93380249]\n",
      "  [ 0.65812436 -1.68136343  0.99296283]\n",
      "  [ 0.65812436 -1.68136343  0.99296283]\n",
      "  [-0.84560716 -0.43266551  1.09092011]\n",
      "  [ 0.23538442  0.08246597  1.19941157]\n",
      "  [-0.28339739 -3.33845653 -0.54183886]]\n",
      "\n",
      " [[-0.80577191  0.52229679  0.93380249]\n",
      "  [-0.84560716 -0.43266551  1.09092011]\n",
      "  [-0.28339739 -3.33845653 -0.54183886]\n",
      "  [-0.80577191  0.52229679  0.93380249]\n",
      "  [ 0.18173485 -0.04901824 -0.57453806]\n",
      "  [-0.84560716 -0.43266551  1.09092011]\n",
      "  [-0.28339739 -3.33845653 -0.54183886]\n",
      "  [-0.2683122  -0.23485634  0.75907219]]\n",
      "\n",
      " [[ 0.18173485 -0.04901824 -0.57453806]\n",
      "  [-0.24423481  0.58242155  0.9500426 ]\n",
      "  [-0.30975785  0.99402065 -1.20278396]\n",
      "  [-0.80577191  0.52229679  0.93380249]\n",
      "  [-0.84560716 -0.43266551  1.09092011]\n",
      "  [ 0.65812436 -1.68136343  0.99296283]\n",
      "  [-0.24423481  0.58242155  0.9500426 ]\n",
      "  [ 0.23538442  0.08246597  1.19941157]]\n",
      "\n",
      " [[ 0.23538442  0.08246597  1.19941157]\n",
      "  [-0.84560716 -0.43266551  1.09092011]\n",
      "  [-0.28339739 -3.33845653 -0.54183886]\n",
      "  [-0.80577191  0.52229679  0.93380249]\n",
      "  [ 0.65812436 -1.68136343  0.99296283]\n",
      "  [-0.28339739 -3.33845653 -0.54183886]\n",
      "  [ 0.18173485 -0.04901824 -0.57453806]\n",
      "  [ 0.65812436 -1.68136343  0.99296283]]\n",
      "\n",
      " [[-0.30975785  0.99402065 -1.20278396]\n",
      "  [ 0.23538442  0.08246597  1.19941157]\n",
      "  [ 0.23538442  0.08246597  1.19941157]\n",
      "  [-0.2683122  -0.23485634  0.75907219]\n",
      "  [ 0.18173485 -0.04901824 -0.57453806]\n",
      "  [-0.24423481  0.58242155  0.9500426 ]\n",
      "  [-0.28339739 -3.33845653 -0.54183886]\n",
      "  [-0.28339739 -3.33845653 -0.54183886]]]\n",
      "6.10528313007\n",
      "RNN/BasicRNNCell/Linear/Matrix:0\n",
      "[[ 0.0487091   0.32617978 -0.26728745  0.51226454]\n",
      " [ 0.4975458  -0.16292982  0.14261477 -0.32775593]\n",
      " [ 0.12126241  0.31377594  0.56934597 -0.15090656]\n",
      " [-0.26042383 -0.0247931   0.32724823  0.11904673]\n",
      " [-0.21392004 -0.1861104  -0.36388233 -0.19884675]\n",
      " [-0.53348554  0.63406174  0.3650501  -0.40542105]\n",
      " [ 0.3093558   0.15500596 -0.49971354  0.10836888]]\n",
      "RNN/BasicRNNCell/Linear/Bias:0\n",
      "[ 0.  0.  0.  0.]\n",
      "outputW:0\n",
      "[[ 0.75053971]\n",
      " [-0.3230969 ]\n",
      " [-0.19203034]\n",
      " [-0.25359322]]\n",
      "outputB:0\n",
      "[-0.22863586]\n"
     ]
    }
   ],
   "source": [
    "# data = np.random.randn(batchSize, maxNumSteps, embeddingSize)\n",
    "data = np.random.randint(0, high=vocabulary_size-1, size=(batchSize, maxNumSteps))\n",
    "lens = [maxNumSteps for i in xrange(batchSize)]\n",
    "t = np.random.randn(batchSize)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(initAll)\n",
    "#     e = sess.run(embedding)\n",
    "#     print e\n",
    "#     print data\n",
    "#     s = sess.run(inputData, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print s\n",
    "#     l = sess.run(loss, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print l\n",
    "#     for v in tf.trainable_variables():\n",
    "#         print v.name\n",
    "#         print sess.run(v)\n",
    "#     w = sess.run(outputW)\n",
    "#     b = sess.run(outputB)\n",
    "#     print w\n",
    "#     print b\n",
    "#     r = sess.run(raw_outputs, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print len(r), len(r[0])\n",
    "#     print r[:,-1]\n",
    "#     i = sess.run(index, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print i\n",
    "#     o = sess.run(outputs, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print o\n",
    "#     m = sess.run(tf.matmul(outputs, outputW), feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print m\n",
    "#     p = sess.run(prediction, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print p\n",
    "    sess.run(learningStep, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "    l = sess.run(loss, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "    print l\n",
    "    for v in tf.trainable_variables():\n",
    "        print v.name\n",
    "        print sess.run(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66335526],\n",
       "       [ 0.70219608],\n",
       "       [-0.58211488],\n",
       "       [ 0.07739599],\n",
       "       [ 0.10125138]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(r[:,-1], w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-85b0413392e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtvars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers, not list"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
