{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batchSize = 5\n",
    "maxNumSteps = 8\n",
    "embeddingSize = 3\n",
    "nNeurons = 4\n",
    "vocabulary_size = 10\n",
    "initEmbeddings = np.random.randn(vocabulary_size, embeddingSize)\n",
    "bias_trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "inputTokens = tf.placeholder(tf.int32, [batchSize, maxNumSteps])\n",
    "inputLens = tf.placeholder(tf.int32, [batchSize])\n",
    "targets = tf.placeholder(tf.float64, [batchSize])\n",
    "rnnCell = tf.nn.rnn_cell.BasicRNNCell(nNeurons)\n",
    "# initState = rnnCell.zero_state(batchSize, tf.float64)\n",
    "# initState = tf.get_variable(\"initState\", [batchSize, nNeurons], dtype=tf.float64, trainable=True)\n",
    "initState = tf.get_variable(\"initState\", [nNeurons], dtype=tf.float64, trainable=True)\n",
    "initStates = tf.concat(0, [initState for i in xrange(batchSize)])\n",
    "initStates = tf.reshape(initStates, [-1, nNeurons])\n",
    "\n",
    "embedding = tf.Variable(initEmbeddings, name='inputEmbeddings', trainable=False, dtype=tf.float64)\n",
    "inputData = tf.nn.embedding_lookup(embedding, inputTokens)\n",
    "\n",
    "raw_outputs, last_states = tf.nn.dynamic_rnn(\n",
    "    cell=rnnCell,\n",
    "    initial_state=initStates,\n",
    "    dtype=tf.float64,\n",
    "    sequence_length=inputLens,\n",
    "    inputs=inputData)\n",
    "    \n",
    "flattened_outputs = tf.reshape(raw_outputs, [-1, nNeurons])\n",
    "index = tf.range(0, batchSize) * maxNumSteps + inputLens - 1\n",
    "outputs = tf.gather(flattened_outputs, index)\n",
    "outputW = tf.get_variable(\"outputW\", [nNeurons, 1], dtype=tf.float64)\n",
    "outputB = tf.get_variable(\"outputB\", [1], dtype=tf.float64)\n",
    "prediction = tf.add(tf.matmul(outputs, outputW), outputB)\n",
    "loss = tf.reduce_sum(tf.pow(prediction-targets, 2)/batchSize)\n",
    "\n",
    "lr = tf.Variable(0.1, trainable=False)\n",
    "tvars = tf.trainable_variables()\n",
    "if not bias_trainable:\n",
    "    tvars = np.take(tvars, [0,1,3,4]).tolist() # exclude RNN bias from training\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "learningStep = optimizer.minimize(loss, var_list=tvars)\n",
    "initAll = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initState:0\n",
      "[ 1.46410907 -0.63501613 -0.24634122 -0.29501   ]\n",
      "RNN/BasicRNNCell/Linear/Matrix:0\n",
      "[[-0.01703865  0.43892278  0.50730039  0.42165349]\n",
      " [ 0.25936399  0.43430144  0.00343578  0.06466562]\n",
      " [ 0.43580867  0.61887269 -0.6188308   0.07348994]\n",
      " [-0.26377648 -0.41525456 -0.30676125 -0.42555988]\n",
      " [-0.53021303  0.36482772  0.03989031 -0.17272379]\n",
      " [-0.22105937 -0.24776662 -0.19847863 -0.03338807]\n",
      " [ 0.52217622 -0.27809662 -0.46751162  0.19431991]]\n",
      "RNN/BasicRNNCell/Linear/Bias:0\n",
      "[ 0.  0.  0.  0.]\n",
      "outputW:0\n",
      "[[ 0.80211346]\n",
      " [ 0.2293196 ]\n",
      " [ 0.70090983]\n",
      " [-0.20661571]]\n",
      "outputB:0\n",
      "[-1.14146178]\n",
      "6.18506051651\n",
      "initState:0\n",
      "[ 1.47123468 -0.63098721 -0.24048359 -0.29496161]\n",
      "RNN/BasicRNNCell/Linear/Matrix:0\n",
      "[[-0.21547607  0.34160228  0.3690477   0.39353471]\n",
      " [-0.29171587  0.14842786 -0.56030575  0.07662606]\n",
      " [ 0.32727858  0.70402887 -0.98735605  0.03034594]\n",
      " [ 0.06416492 -0.2610832   0.01334147 -0.46709646]\n",
      " [ 0.10560379  0.58607889  0.71631451 -0.34082643]\n",
      " [ 0.18353758 -0.18334824  0.15375016 -0.02323362]\n",
      " [ 0.88981361 -0.16402982 -0.12821005  0.18345435]]\n",
      "RNN/BasicRNNCell/Linear/Bias:0\n",
      "[ 0.  0.  0.  0.]\n",
      "outputW:0\n",
      "[[ 0.22136527]\n",
      " [-0.05818206]\n",
      " [ 0.65580704]\n",
      " [-0.4670228 ]]\n",
      "outputB:0\n",
      "[ 0.93014542]\n"
     ]
    }
   ],
   "source": [
    "# data = np.random.randn(batchSize, maxNumSteps, embeddingSize)\n",
    "data = np.random.randint(0, high=vocabulary_size-1, size=(batchSize, maxNumSteps))\n",
    "lens = [maxNumSteps for i in xrange(batchSize)]\n",
    "t = np.random.randn(batchSize)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(initAll)\n",
    "#     e = sess.run(embedding)\n",
    "#     print e\n",
    "#     print data\n",
    "#     s = sess.run(inputData, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print s\n",
    "#     l = sess.run(loss, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print l\n",
    "    for v in tf.trainable_variables():\n",
    "        print v.name\n",
    "        print sess.run(v)\n",
    "#     w = sess.run(outputW)\n",
    "#     b = sess.run(outputB)\n",
    "#     print w\n",
    "#     print b\n",
    "#     r = sess.run(raw_outputs, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print len(r), len(r[0])\n",
    "#     print r[:,-1]\n",
    "#     i = sess.run(index, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print i\n",
    "#     o = sess.run(outputs, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print o\n",
    "#     m = sess.run(tf.matmul(outputs, outputW), feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print m\n",
    "#     p = sess.run(prediction, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "#     print p\n",
    "    sess.run(learningStep, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "    l = sess.run(loss, feed_dict={inputTokens:data, inputLens:lens, targets:t})\n",
    "    print l\n",
    "    for v in tf.trainable_variables():\n",
    "        print v.name\n",
    "        print sess.run(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initState:0\n",
      "RNN/BasicRNNCell/Linear/Matrix:0\n",
      "RNN/BasicRNNCell/Linear/Bias:0\n",
      "outputW:0\n",
      "outputB:0\n"
     ]
    }
   ],
   "source": [
    "for v in tf.trainable_variables():\n",
    "    print v.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  4],\n",
       "       [11, 10]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot([[1,2],[3,4]], [[1,2],[2,1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
